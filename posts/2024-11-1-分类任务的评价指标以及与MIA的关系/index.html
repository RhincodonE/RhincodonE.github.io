<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h1 id="机器学习模型评估指标详解">机器学习模型评估指标详解</h1> <p>以下是机器学习模型常用评估指标的详细说明，包括<strong>准确率</strong>、<strong>精确率</strong>、<strong>召回率</strong>、<strong>F1 值</strong>、<strong>AUC</strong> 和 <strong>G-mean</strong> 的定义、优缺点。</p> <hr> <h3 id="1-准确率-accuracy">1. 准确率 (Accuracy)</h3> <ul> <li> <p><strong>定义</strong>：准确率是模型预测正确的样本占所有样本的比例。 \(\text{Accuracy} = \frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}}\) 其中，TP 为真正例，TN 为真负例，FP 为假正例，FN 为假负例。</p> </li> <li> <strong>优点</strong>：简单直观，适用于类别分布均衡的数据集。</li> <li> <strong>缺点</strong>：对于类别不平衡的数据集效果较差，因为少数类的错误可能被多数类的正确预测掩盖。</li> </ul> <hr> <h3 id="2-精确率-precision">2. 精确率 (Precision)</h3> <ul> <li> <p><strong>定义</strong>：精确率表示在预测为正类的样本中，真正为正类的比例。 \(\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}\)</p> </li> <li> <strong>优点</strong>：在对误报容忍度较低的应用中（如癌症检测或欺诈检测）尤为重要。</li> <li> <strong>缺点</strong>：当负类样本非常多而正类样本很少时，精确率可能较高，导致对召回率的忽视。</li> </ul> <hr> <h3 id="3-召回率-recall">3. 召回率 (Recall)</h3> <ul> <li> <p><strong>定义</strong>：召回率表示所有实际为正类的样本中被正确预测为正类的比例。 \(\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}\)</p> </li> <li> <strong>优点</strong>：在对漏报敏感的应用（如疾病检测）中效果显著。</li> <li> <strong>缺点</strong>：当模型倾向于将样本预测为正类时，召回率可能较高，但精确率会下降。</li> </ul> <hr> <h3 id="4-f1-值-f1-score">4. F1 值 (F1 Score)</h3> <ul> <li> <p><strong>定义</strong>：F1 值是精确率和召回率的调和平均值，用于综合评估模型的精确度和召回度。 \(\text{F1 Score} = 2 \cdot \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}\)</p> </li> <li> <strong>优点</strong>：适用于类别不平衡的数据集，因为它权衡了精确率和召回率。</li> <li> <strong>缺点</strong>：不适用于只关注精确率或召回率的应用场景，因为它无法提供各个指标的详细信息。</li> </ul> <hr> <h3 id="5-auc-area-under-curve">5. AUC (Area Under Curve)</h3> <ul> <li> <p><strong>定义</strong>：AUC 表示 ROC 曲线下的面积，ROC 曲线是通过绘制不同阈值下的 TPR（真正率）和 FPR（假正率）得到的曲线。 \(\text{AUC} = \int \text{ROC Curve}\)</p> </li> <li> <strong>优点</strong>：不受类别分布影响，能够直观衡量模型的分类能力。AUC 越接近 1，模型效果越好。</li> <li> <strong>缺点</strong>：对于类别不平衡严重的情况，AUC 可能掩盖少数类的错误分类问题。</li> </ul> <hr> <h3 id="6-g-mean-几何平均">6. G-Mean (几何平均)</h3> <ul> <li> <p><strong>定义</strong>：G-mean 是模型在正类和负类上的分类效果的几何平均值，通常用于处理类别不平衡的数据。 \(\text{G-Mean} = \sqrt{\text{Recall}_{\text{positive}} \times \text{Recall}_{\text{negative}}}\)</p> </li> <li> <strong>优点</strong>：能够平衡模型在不同类别上的表现，适用于类别不平衡的情况。</li> <li> <strong>缺点</strong>：可能在极端不平衡数据上表现不佳，因为少数类的表现过于依赖召回率。</li> </ul> <hr> <h3 id="总结">总结</h3> <table> <thead> <tr> <th>指标</th> <th>定义</th> <th>优点</th> <th>缺点</th> </tr> </thead> <tbody> <tr> <td>准确率</td> <td>所有正确预测的样本占所有样本的比例</td> <td>直观简单，适用于类别平衡的数据集</td> <td>类别不平衡时效果差</td> </tr> <tr> <td>精确率</td> <td>预测为正类的样本中真正为正类的比例</td> <td>适用于误报容忍度低的场景</td> <td>容易忽视召回率</td> </tr> <tr> <td>召回率</td> <td>实际为正类的样本中被正确预测为正类的比例</td> <td>适用于漏报敏感的场景</td> <td>容易忽视精确率</td> </tr> <tr> <td>F1 值</td> <td>精确率和召回率的调和平均值</td> <td>平衡精确率和召回率，适用于类别不平衡的数据</td> <td>无法提供精确率和召回率的详细信息</td> </tr> <tr> <td>AUC</td> <td>ROC 曲线下面积，表示模型对不同阈值下的整体表现</td> <td>不受类别分布影响，能够直观衡量模型分类能力</td> <td>严重不平衡数据时可能掩盖少数类错误</td> </tr> <tr> <td>G-Mean</td> <td>正类和负类召回率的几何平均值，适用于类别不平衡数据</td> <td>平衡模型在不同类别上的表现</td> <td>在极端不平衡数据上表现可能不佳</td> </tr> </tbody> </table> <hr> <h2 id="tprfprtnrfnrl2-error-和-l1-error">TPR、FPR、TNR、FNR、L2 Error 和 L1 Error</h2> <h3 id="1-tpr-true-positive-rate">1. TPR (True Positive Rate)</h3> <ul> <li> <strong>定义</strong>：TPR（真正例率）是所有实际为正类的样本中被正确预测为正类的比例，等同于<strong>召回率</strong>。 \(\text{TPR} = \frac{\text{TP}}{\text{TP} + \text{FN}}\)</li> </ul> <h3 id="2-fpr-false-positive-rate">2. FPR (False Positive Rate)</h3> <ul> <li> <strong>定义</strong>：FPR（假正例率）是所有实际为负类的样本中被错误预测为正类的比例。 \(\text{FPR} = \frac{\text{FP}}{\text{FP} + \text{TN}}\)</li> </ul> <h3 id="3-tnr-true-negative-rate">3. TNR (True Negative Rate)</h3> <ul> <li> <strong>定义</strong>：TNR（真负例率）是所有实际为负类的样本中被正确预测为负类的比例，也称<strong>特异性</strong>。 \(\text{TNR} = \frac{\text{TN}}{\text{TN} + \text{FP}}\)</li> </ul> <h3 id="4-fnr-false-negative-rate">4. FNR (False Negative Rate)</h3> <ul> <li> <strong>定义</strong>：FNR（假负例率）是所有实际为正类的样本中被错误预测为负类的比例。 \(\text{FNR} = \frac{\text{FN}}{\text{FN} + \text{TP}}\)</li> </ul> <h3 id="5-l2-error-mean-squared-error-mse">5. L2 Error (Mean Squared Error, MSE)</h3> <ul> <li> <strong>定义</strong>：L2误差是预测值与实际值之间差值的平方和的均值。 \(\text{L2 Error} = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2\)</li> </ul> <h3 id="6-l1-error-mean-absolute-error-mae">6. L1 Error (Mean Absolute Error, MAE)</h3> <ul> <li> <strong>定义</strong>：L1误差是预测值与实际值之间差值的绝对值的均值。 \(\text{L1 Error} = \frac{1}{n} \sum_{i=1}^n |y_i - \hat{y}_i|\)</li> </ul> <hr> <h2 id="为什么在-mia-中更关注低-fpr-下的-tpr">为什么在 MIA 中更关注低 FPR 下的 TPR？</h2> <p>在<strong>成员推断攻击</strong>（Membership Inference Attack, MIA）中，更关注在低 FPR（False Positive Rate）下的 TPR（True Positive Rate）。原因包括：</p> <ol> <li> <strong>隐私风险</strong>：低 FPR 能降低误判非成员为成员的可能性。</li> <li> <strong>误报影响</strong>：高 FPR 会导致大量误报，掩盖攻击模型的真实效果。</li> <li> <strong>攻击强度</strong>：在极少误报情况下，高 TPR 表示攻击模型在严格条件下的攻击强度。</li> <li> <strong>防御敏感性</strong>：低 FPR 下的 TPR 能更好地评估防御机制的有效性。</li> <li> <strong>实际需求</strong>：在金融或医疗领域，低 FPR 的高 TPR 更符合实际隐私需求。</li> </ol> <p>低 FPR 下的 TPR 能帮助揭示模型在严格隐私保护条件下的风险。</p> </body></html>